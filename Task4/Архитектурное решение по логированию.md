# Архитектурное решение по логированию

## 1 Что и где логировать (по системам)
Цель: обеспечить воспроизводимость событий по заказу и диагностировать сбои/аномалии Логи структурированные (JSON), с корреляцией через trace_id и order_id

Системы и источники логов (отметить на C4‑диаграмме):
- Интернет‑магазин (Frontend Vue, Backend Spring Boot)
- MES (Frontend React, Backend C#)
- CRM (Frontend Vue, Backend Spring Boot)
- Интеграции и шина (RabbitMQ)
- Базы данных (аудит SQL/медленные запросы), кэши
- Балансировщики/шлюзы (Ingress/Nginx)

Список ключевых событий уровня INFO (обязательно):
- Создание заказа: order_id, user_id/partner_id, channel (b2c|b2b), cart_id, сумма/валюта (без деталей платежа), trace_id
- Изменение статуса заказа: order_id, from_status, to_status, причина/инициатор, trace_id, elapsed_ms
- Публикация/получение сообщения в RabbitMQ: order_id, exchange, routing_key, message_id, retry_count, trace_id
- Запуск/завершение расчёта стоимости: order_id, job_id, model_id, poly_count_bucket, duration_ms, outcome (success|fail), trace_id
- Ошибки валидации API/контрактов: endpoint, метод, причина, partner_id, trace_id
- Аутентификация/авторизация (без ПД): subject_id, роль, результат, trace_id
- Дашборд MES: запросы и пагинация, сегменты/фильтры, время ответа

Другие уровни логирования и когда использовать:
- DEBUG: детальная диагностика (включается временно через флаги/фильтры в конкретных сервисах и окружениях)
- WARN: потенциальные проблемы (ретраи, депрецированные контракты, лаги реплик, повышенная латентность)
- ERROR: исключения, отказ операций, попадание в DLQ, недоступность зависимостей
- FATAL (если поддерживается): критические отказы, невозможность старта сервиса

Обязательные поля логов:
- timestamp, level, service, environment, instance, trace_id, span_id, order_id, partner_id (если есть), message_id (если MQ), user_segment (anon|auth|operator), ip (обезличенный), error_code/error_class

## 2 Мотивация
Логирование позволит:
- Сократить MTTR и устранить «невоспроизводимые» инциденты (поиск причины по логам и трейсам)
- Снизить долю потерянных заказов (детект неуспешных публикаций/обработок, DLQ)
- Повысить SLA по API и расчётам (корреляция ошибок с нагрузкой, быстрые хотфиксы)
- Улучшить UX операторов (диагностика медленных мест дашборда)

Ключевые метрики влияния:
- MTTR по инцидентам
- Error rate по API и воркерам MES
- Доля сообщений, попавших в DLQ/обработанных ретраем
- Время от SUBMITTED до PRICE_CALCULATED

Приоритет внедрения (логирование/трейсинг сначала):
1) MES backend и воркеры расчётов (самое узкое место и источник задержек)
2) RabbitMQ (publish/consume/DLQ) - потери сообщений
3) Shop/CRM API - крайние точки создания/закрытия заказов (бизнес‑критичные действия)
4) Дашборд MES - влияние на работу операторов

## 3 Предлагаемое решение
Технологический стек (два допустимых варианта):
- Вариант A: OpenTelemetry Logs/Collector → Elasticsearch/OpenSearch → Kibana/OpenSearch Dashboards
- Вариант B: Promtail/OTel → Grafana Loki → Grafana

Рекомендуемый: OpenSearch + OpenTelemetry Collector (шире экосистема для поиска/анализ/алертов) Для лёгких сред - Loki

Компоненты и интеграции:
- Приложения пишут структурированный JSON лог (серверный): через OTel logger или стандартный логгер + exporter (Filebeat/OTel Collector)
- Frontend: технические логи (без ПД) - в меньшем объёме, корреляция с trace_id
- RabbitMQ: включить логирование событий (connections, channels, перезапуски, policy)
- DB: slow query log, аудит схемы/DDL (по белому списку); избегать логирования данных
- Ingress/Nginx: access/error логи c trace_id
- OpenTelemetry Collector: парсинг/нормализация, маскировка ПД (grok/processors), маршрутизация в хранилище
- Хранилище логов: OpenSearch (инфра/прод), ротация индексов, S3 сжимаемые снапшоты

Политика безопасности:
- Запрет ПД в логах (маскировка номеров телефонов/почты/адресов, токенов, cookie)
- Шифрование TLS, доступ к логам по SSO (OIDC) и RBAC: роли Support, Dev, SRE, Product
- Аудит доступа к логам (кто, когда, какие индексы)

Политика хранения и индексы:
- Индексация по доменам: logs-api-*, logs-mes-*, logs-rabbit-*, logs-db-*, logs-ingress-*, logs-frontend-*
- Ретенция: горячие 14–30 дней, тёплые 90 дней, холодные архивы в S3 до 365 дней (по согласованию)
- Размеры: целевой объём в горячем слое ≤ 500 GB/индекс; ILM/ISM политики, rollover по 30–50 GB/индекс
- Сжатие и downsampling для DEBUG/TRACE уровней

## 4 От сбора логов к анализу
Алертинг (в Kibana/Grafana):
- Spikes ошибок: ERROR/FATAL рост > X/min по сервису
- DLQ события: количество записей > 0 в окне 5 минут
- Валидационные ошибки партнёров: рост 4xx/контрактных ошибок у конкретного partner_id
- Медленные операции: шаблонные сообщения о запросах > SLO
- Аномалии: резкий рост events/sec по «созданию заказов» (возможный DDoS/боты)

Поиск аномалий и расследование:
- ML/Anomaly Detection в OpenSearch
- Корреляция логов с трейсам/метриками через trace_id
- Дашборды с топ‑N ошибок по endpoint/partner_id/queue

Операционные практики:
- Гайды на типовые алерты (DLQ, рост пиков 5xx, медленные запросы)
- Быстрые saved-search и фильтры (order_id, partner_id, trace_id)
- Регулярные пост‑мортемы и корректировка уровней логирования

## 5 Критерии выбора технологии (плюсы/минусы)
Критерии:
1) Стоимость владения (TCO) и ретенция: цена за хранение/индексы/трафик
2) Производительность поиска и горизонтальная масштабируемость
3) Поддержка схемы/инструментации (OTel, JSON, парсинг), удобство парсинга логов
4) Безопасность и контроль доступа (SSO/RBAC, аудит)
5) Интеграции с метриками/трейсингом, алерты и anomaly detection
6) Эксплуатация (управление ILM/ISM, бэкапы, миграции, обновления)

Сравнение кратко:
- OpenSearch/Elasticsearch:
  - + мощный поиск, зрелые индексы/ILM, поддержка ML/AD, богатый UI (Kibana/OpenSearch Dashboards)
  - − требовательность к ресурсам, стоимость кластера, сложность тюнинга
- Grafana Loki:
  - + экономный по хранению (label index + chunks), дешевле в эксплуатации, проста интеграция с Grafana
  - − поиск по содержимому ограничен, слабее аналитика и ML, нет полноценной схемы индексов
- Облако (Yandex Managed Log/ELK):
  - + меньше DevOps‑нагрузки, SLA провайдера
  - − зависимость от провайдера и ценообразования, ограничения фич

Рекомендация:
- OpenSearch (Managed или self‑hosted) + OTel Collector
- Корреляция логов с трейсами и метриками через Grafana
